{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7vF0FMaGQc-6"
   },
   "source": [
    "## Principal component analysis (PCA)\n",
    "\n",
    "É uma redução de dimensionalidade linear que utiliza a Decomposição em Valores Singulares dos dados para projetá-los em um espaço dimensões menor.\n",
    "\n",
    "Um vetor (não nulo) $\\mathbf{v}$ com dimensão $N$ é um \\textbf{autovetor} da matriz quadrada $\\mathbf{A}$ com dimensões $N \\times N$ se satisfaz a equação linear:\n",
    "\n",
    "$\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}$\n",
    "\n",
    "onde $\\lambda$ é um escalar chamado autovalor de $\\mathbf{v}$. \n",
    "\n",
    "- Os autovetores provocam transformações lineares na matriz $\\mathbf{A}$ que alongam ou comprimem os diferentes eixos coordenados.\n",
    "- A \"força\" da transformação é quantificada pelo autovalor. \n",
    "\n",
    "Também definido como:\n",
    "\n",
    "$(\\mathbf{A} - \\lambda_i \\mathbf{I}) \\mathbf{v} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2vwGGXIO-wd"
   },
   "source": [
    "Decomposição SVD (singular value decomposition) \n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Singular_value_decomposition_visualisation.svg/800px-Singular_value_decomposition_visualisation.svg.png width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ug1jJRAkuVH"
   },
   "source": [
    "## PCA\n",
    "\n",
    "O objetivo do PCA é reduzir a dimensão dos dados para um conjunto de variáveis ​​mais gerenciável. \n",
    "\n",
    "Vantagens:\n",
    "- $\\textbf{não supervisionado}$\n",
    "- visualização\n",
    "- eliminar redundâcia\n",
    "- evitar dados esparso\n",
    "- melhorar a classificação\n",
    "- explorar a relação entre as variáveis\n",
    "\n",
    "Cada componentes principal é a combinação linear ponderada dos preditores oiginais: \n",
    "\n",
    "$Z_i = w_{i1} X_1 + w_{i2} X_2$ para i=1\n",
    "\n",
    "$Z_i = w_{i1} X_1 + w_{i2} X_2$ para i=2\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1594830419655,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "keXibJwfkp08"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data: [[-1 -1]\n [-2 -1]\n [-3 -2]\n [ 1  1]\n [ 2  1]\n [ 3  2]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "print('data:', X)\n",
    "\n",
    "# fig = plt.figure(figsize=(20,5))\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.scatter(X[:,0],X[:,1],s=40)\n",
    "# plt.xlim([-3,3])\n",
    "# plt.ylim([-3,3])\n",
    "\n",
    "\n",
    "# pca = PCA(n_components=1)\n",
    "# pca.fit(X)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.singular_values_)\n",
    "\n",
    "# # formato\n",
    "# #   linhas: componentes\n",
    "# #   colunas: variaveis\n",
    "# print(pca.components_)\n",
    "\n",
    "# delta_1 = pca.components_[0,1]/pca.components_[0,0]\n",
    "\n",
    "# x = np.arange(-3,5)\n",
    "# y = np.arange(-3,5)\n",
    "\n",
    "# plt.subplot(1,3,2)\n",
    "# plt.plot(X[:,0],X[:,1],'o')\n",
    "# plt.plot(x,delta_1*y,'-.')\n",
    "# plt.xlim([-3.5,3.5])\n",
    "# plt.ylim([-3.5,3.5])\n",
    "\n",
    "\n",
    "# X_t = pca.transform(X)\n",
    "# print('reduced data',X_t)\n",
    "\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.plot(X_t,np.zeros((6)),'-.o')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zr2WPUwWp78I"
   },
   "source": [
    "### Efeito de uma feature sem variânça\n",
    "\n",
    "$Z_i = w_{i1} X_1 + w_{i2} X_2 + w_{i3} X_3$\n",
    "\n",
    "$Z_i = w_{i1} X_1 + w_{i2} X_2 + w_{i3} X_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1594830431094,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "zd6DsybMtOVn"
   },
   "outputs": [],
   "source": [
    "# X = \n",
    "# print('data:',X)\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = plt.axes(projection=\"3d\")\n",
    "# ax.scatter3D(X[:,0],X[:,1],X[:,2], c='blue', s=40, depthshade=False);\n",
    "# plt.xlim([-3,3])\n",
    "# plt.ylim([-3,3])\n",
    "# plt.show()\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(X)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# # formato\n",
    "# #   linhas: componentes\n",
    "# #   colunas: variaveis\n",
    "# print(pca.components_)\n",
    "\n",
    "# delta_1 = pca.components_[0,1]/pca.components_[0,0]\n",
    "# delta_2 = pca.components_[1,1]/pca.components_[1,0]\n",
    "\n",
    "# x = np.arange(-3,5)\n",
    "# y = np.arange(-3,5)\n",
    "\n",
    "# fig = plt.figure(figsize=(11,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(X[:,0],X[:,1],'o')\n",
    "# plt.plot(x,delta_1*y,'-.')\n",
    "# plt.plot(x,delta_2*y,'-.')\n",
    "# plt.xlim([-4,4])\n",
    "# plt.ylim([-4,4])\n",
    "\n",
    "# X_t = pca.transform(X)\n",
    "# print('reduced data',X_t)\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(X_t[:,0],X_t[:,1],'o')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oR_aOmR2KLXZ"
   },
   "source": [
    "## Vamos trabalhar (explorar) o dataset 'wine'\n",
    "\n",
    "Abstract: Using chemical analysis determine the origin of wines\n",
    "\t\n",
    "https://archive.ics.uci.edu/ml/datasets/wine\n",
    "\n",
    "The attributes are:\n",
    "- Alcohol\n",
    "- Malic acid\n",
    "- Ash\n",
    "- Alcalinity of ash\n",
    "- Magnesium\n",
    "- Total phenols\n",
    "- Flavanoids\n",
    "- Nonflavanoid phenols\n",
    "- Proanthocyanins\n",
    "- Color intensity\n",
    "- Hue\n",
    "- OD280/OD315 of diluted wines\n",
    "- Proline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1324,
     "status": "aborted",
     "timestamp": 1594830420154,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "Iq-MpDxj1Fll"
   },
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from sklearn import datasets\n",
    "\n",
    "# wine = datasets.load_wine()\n",
    "# X = wine.data\n",
    "# label = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1318,
     "status": "aborted",
     "timestamp": 1594830420159,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "qD04DdSa2i8q"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(22, 13))\n",
    "# for i in range(1,X.shape[1]):\n",
    "#   plt.subplot(3,4,i)\n",
    "#   plt.scatter(X[:, 0], X[:, i], c=label, cmap=plt.cm.Set1, edgecolor='k')\n",
    "#   plt.xlabel(wine.feature_names[0])\n",
    "#   plt.ylabel(wine.feature_names[i])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1314,
     "status": "aborted",
     "timestamp": 1594830420163,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "3EoiSqKEKc35"
   },
   "outputs": [],
   "source": [
    "# # To getter a better understanding of interaction of the dimensions\n",
    "# # plot the first three PCA dimensions\n",
    "# fig = plt.figure(figsize=(12,12))\n",
    "# ax = plt.axes(projection=\"3d\")\n",
    "# ax.scatter3D(X[:,0],X[:,1],X[:,2], c=label, s=40, depthshade=False);\n",
    "# ax.set_xlabel(wine.feature_names[0])\n",
    "# ax.set_ylabel(wine.feature_names[1])\n",
    "# ax.set_zlabel(wine.feature_names[2])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1310,
     "status": "aborted",
     "timestamp": 1594830420167,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "3Bu8WEcS65Th"
   },
   "outputs": [],
   "source": [
    "# Fit to data and predict using pipelined GNB and PCA.\n",
    "# n_components = 3\n",
    "# pca = PCA(n_components=n_components)\n",
    "# pca.fit(X)\n",
    "# X_t = pca.transform(X)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# # formato\n",
    "# #   linhas: componentes\n",
    "# #   colunas: variaveis\n",
    "# # print(pca.components_.shape)\n",
    "# names = ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', \n",
    "#        'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'diluted_wines', 'proline']\n",
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# for i in range(n_components):\n",
    "#   plt.subplot(n_components,1,i+1)\n",
    "#   plt.bar(np.arange(13),pca.components_[i,:])\n",
    "#   plt.hlines(0,-0.5, 12.5)\n",
    "#   plt.xlim([-0.5, 12.5])\n",
    "#   plt.ylabel('componente_'+str(i+1))\n",
    "#   plt.xticks(np.arange(13),names,rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Q8v16t2F-wM"
   },
   "source": [
    "## Efeito da normalização\n",
    "\n",
    "\"Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. $\\textbf{The input data is centered but not scaled}$ for each feature before applying the SVD.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1307,
     "status": "aborted",
     "timestamp": 1594830420171,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "Bf9K-QK30zfy"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # Make a train/test split using 30% test size\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.30, random_state=42)\n",
    "\n",
    "# # Fit to data and predict using pipelined GNB and PCA.\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(X_train)\n",
    "# X_train_pca = pca.transform(X_train)\n",
    "\n",
    "# clf = GaussianNB()\n",
    "# clf.fit(X_train_pca, y_train)\n",
    "# pred_test = clf.predict(pca.transform(X_test))\n",
    "\n",
    "# # Show prediction accuracies in scaled and unscaled data.\n",
    "# print('\\n accuracy com duas compnentes')\n",
    "# print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))\n",
    "\n",
    "# ########################\n",
    "# # agora com scaler\n",
    "\n",
    "# std = StandardScaler()\n",
    "# std.fit(X_train)\n",
    "# X_train_std = std.transform(X_train)\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(X_train_std)\n",
    "# X_train_std_pca = pca.transform(X_train_std)\n",
    "\n",
    "# clf = GaussianNB()\n",
    "# clf.fit(X_train_std_pca, y_train)\n",
    "# pred_test = clf.predict(pca.transform(std.transform(X_test)))\n",
    "\n",
    "# # Show prediction accuracies in scaled and unscaled data.\n",
    "# print('\\n accuracy com duas compnentes mais normalizacao')\n",
    "# print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1304,
     "status": "aborted",
     "timestamp": 1594830420176,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "ueWU53IIFe4D"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap=plt.cm.Set1, edgecolor='k')\n",
    "# plt.xlabel('PCA_1')\n",
    "# plt.ylabel('PCA_2')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.scatter(X_train_std_pca[:, 0], X_train_std_pca[:, 1], c=y_train, cmap=plt.cm.Set1, edgecolor='k')\n",
    "# plt.xlabel('PCA_1')\n",
    "# plt.ylabel('PCA_2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78D_atdqGGha"
   },
   "source": [
    "## Efeito do número de componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1308,
     "status": "aborted",
     "timestamp": 1594830420188,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "Ghj-SQ08izej"
   },
   "outputs": [],
   "source": [
    "# acc = []\n",
    "\n",
    "# for i in range(1,14):\n",
    "#   pca = PCA(n_components=i)\n",
    "#   pca.fit(X_train)\n",
    "#   X_train_pca = pca.transform(X_train)\n",
    "\n",
    "#   clf = GaussianNB()\n",
    "#   clf.fit(X_train_pca, y_train)\n",
    "#   pred_test = clf.predict(pca.transform(X_test))\n",
    "#   acc.append(clf.score(pca.transform(X_test), y_test))\n",
    "\n",
    "# plt.figure(figsize=(22,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(acc,'-o')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(pca.explained_variance_ratio_,'-.*')\n",
    "# plt.ylim([0,0.003])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcUuPqlDQDOF"
   },
   "source": [
    "## Linear Discriminant Analysis For Dimensionality Reduction\n",
    "\n",
    "A Análise Discriminante Linear procura separar (ou discriminar) as amostras no conjunto de dados de treinamento pelo valor das classes. \n",
    "\n",
    "Especificamente, o modelo procura encontrar uma combinação linear de variáveis de entrada que consiga a separação máxima das amostras entre as classes (centróides ou médias de classe) e a separação mínima de amostras dentro de cada classe.\n",
    "\n",
    "LDA possui as mesmas vantagens do PCA mas é supervisionado! Consequentemente, a separação torna-se melhor. \n",
    "\n",
    "O objetivo do LDA é maximizar \n",
    "$S = \\frac{\\sigma^2_{between}}{\\sigma^2_{within}}$\n",
    "\n",
    "Objetivo multiclasse:\n",
    "\n",
    "$S = \\frac{\\mathbf{w}^T \\Sigma_b \\mathbf{w}}{\\mathbf{w}^T \\Sigma \\mathbf{w}}$\n",
    "\n",
    "onde $\\mathbf{w}$ é um autovetor de $ \\Sigma^{-1} \\Sigma_b$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1307,
     "status": "aborted",
     "timestamp": 1594830420190,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "OR-GeLC6jq4V"
   },
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# n_components = 2\n",
    "# pca = PCA(n_components=n_components)\n",
    "# lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "\n",
    "# X_pca = pca.fit(X).transform(X)\n",
    "# X_lda = lda.fit(X, label).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1303,
     "status": "aborted",
     "timestamp": 1594830420194,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "C1-ITn1nPr2p"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=label, cmap=plt.cm.Set1, edgecolor='k')\n",
    "# plt.xlabel('PCA_1')\n",
    "# plt.ylabel('PCA_2')\n",
    "# plt.title('PCA')\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.scatter(X_lda[:, 0], X_lda[:, 1], c=label, cmap=plt.cm.Set1, edgecolor='k')\n",
    "# plt.xlabel('LDA_1')\n",
    "# plt.ylabel('LDA_2')\n",
    "# plt.title('LDA')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbGT0Bl_NlPY"
   },
   "source": [
    "### Calssificação com LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1296,
     "status": "aborted",
     "timestamp": 1594830420195,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "QT6NPxrFP8sC"
   },
   "outputs": [],
   "source": [
    "# # Make a train/test split using 30% test size\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.30, random_state=42)\n",
    "\n",
    "# # Fit to data and predict using pipelined GNB and LDA.\n",
    "# lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "# X_train_lda = lda.fit(X_train, y_train).transform(X_train)\n",
    "\n",
    "\n",
    "# clf = GaussianNB()\n",
    "# clf.fit(X_train_lda, y_train)\n",
    "# pred_test = clf.predict(lda.transform(X_test))\n",
    "\n",
    "# # Show prediction accuracies in scaled and unscaled data.\n",
    "# print('\\n accuracy com duas compnentes')\n",
    "# print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1296,
     "status": "aborted",
     "timestamp": 1594830420198,
     "user": {
      "displayName": "Juan Colonna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4dZjtaXxQYaR-ScIHA_aQ8i-WrfG4CNZI4NzabQ=s64",
      "userId": "08094073493526990064"
     },
     "user_tz": 240
    },
    "id": "zwo3VrkROMFh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPzQ3VUuQmhuV4akxXWlB5I",
   "collapsed_sections": [],
   "name": "PCA_LDA_empty.ipybn",
   "provenance": [
    {
     "file_id": "17uAIQZ3Yjvp0P9AkgioptGPbBwBeTstg",
     "timestamp": 1594829924650
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}